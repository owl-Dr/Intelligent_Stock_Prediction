{"cells":[{"cell_type":"code","execution_count":1,"id":"0fe18f80","metadata":{"id":"0fe18f80","executionInfo":{"status":"ok","timestamp":1725097443493,"user_tz":-330,"elapsed":9095,"user":{"displayName":"Harshit","userId":"17422353300963922472"}}},"outputs":[],"source":["import numpy as np\n","import random\n","import pandas as pd\n","\n","import datetime\n","import math, time\n","import itertools\n","import datetime\n","from operator import itemgetter\n","from sklearn.metrics import mean_squared_error\n","from sklearn.preprocessing import MinMaxScaler\n","from math import sqrt\n","import torch\n","import torch.nn as nn\n","from torch.autograd import Variable\n","\n","import matplotlib.pyplot as plt\n","import os"]},{"cell_type":"code","execution_count":2,"id":"O_AB6XHC75R1","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O_AB6XHC75R1","outputId":"663c8aec-855c-4cb5-ab6f-3d94d8ced745","executionInfo":{"status":"ok","timestamp":1725097479854,"user_tz":-330,"elapsed":36383,"user":{"displayName":"Harshit","userId":"17422353300963922472"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"id":"5a56ee39","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5a56ee39","executionInfo":{"status":"ok","timestamp":1725097481045,"user_tz":-330,"elapsed":1199,"user":{"displayName":"Harshit","userId":"17422353300963922472"}},"outputId":"d2573228-5b39-4aff-e3f2-7e69e9b3a07a"},"outputs":[{"output_type":"stream","name":"stdout","text":["['ADANIPORTS.csv', 'ASIANPAINT.csv', 'AXISBANK.csv', 'BAJAJ-AUTO.csv', 'BAJAJFINSV.csv', 'BAJFINANCE.csv', 'BHARTIARTL.csv', 'BPCL.csv', 'BRITANNIA.csv', 'CIPLA.csv', 'COALINDIA.csv', 'DRREDDY.csv', 'EICHERMOT.csv', 'GAIL.csv', 'GRASIM.csv', 'HCLTECH.csv', 'HDFC.csv', 'HDFCBANK.csv', 'HEROMOTOCO.csv', 'HINDALCO.csv', 'HINDUNILVR.csv', 'ICICIBANK.csv', 'INDUSINDBK.csv', 'INFY.csv', 'IOC.csv', 'ITC.csv', 'JSWSTEEL.csv', 'KOTAKBANK.csv', 'LT.csv', 'MARUTI.csv', 'MM.csv', 'NESTLEIND.csv', 'NTPC.csv', 'ONGC.csv', 'POWERGRID.csv', 'RELIANCE.csv', 'SBIN.csv', 'SHREECEM.csv', 'SUNPHARMA.csv', 'TATAMOTORS.csv', 'TATASTEEL.csv', 'TCS.csv', 'TECHM.csv', 'TITAN.csv', 'ULTRACEMCO.csv', 'UPL.csv', 'VEDL.csv', 'WIPRO.csv', 'ZEEL.csv']\n"]}],"source":["dpath = \"/content/drive/My Drive/LAB/data/\"\n","files = os.listdir(dpath)\n","files.sort()\n","print(files)"]},{"cell_type":"code","execution_count":4,"id":"6384bafa","metadata":{"id":"6384bafa","executionInfo":{"status":"ok","timestamp":1725097481045,"user_tz":-330,"elapsed":5,"user":{"displayName":"Harshit","userId":"17422353300963922472"}}},"outputs":[],"source":["df = pd.read_csv(dpath + files[0]).set_index('Date')\n","df = df[['Close']]"]},{"cell_type":"code","execution_count":5,"id":"63f2911f","metadata":{"id":"63f2911f","executionInfo":{"status":"ok","timestamp":1725097481616,"user_tz":-330,"elapsed":575,"user":{"displayName":"Harshit","userId":"17422353300963922472"}}},"outputs":[],"source":["scaler = MinMaxScaler(feature_range=(-1, 1))\n","df['Close'] = scaler.fit_transform(df['Close'].values.reshape(-1,1))"]},{"cell_type":"code","execution_count":6,"id":"d3a56355","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d3a56355","executionInfo":{"status":"ok","timestamp":1725097481617,"user_tz":-330,"elapsed":9,"user":{"displayName":"Harshit","userId":"17422353300963922472"}},"outputId":"856c7c46-d25d-48ad-885c-2ff647427966"},"outputs":[{"output_type":"stream","name":"stdout","text":["x_train.shape =  (2634, 29, 1)\n","y_train.shape =  (2634, 1)\n","x_test.shape =  (658, 29, 1)\n","y_test.shape =  (658, 1)\n"]}],"source":["def load_data(stock, look_back):\n","    data_raw = stock.values # convert to numpy array\n","    data = []\n","\n","    # create all possible sequences of length look_back\n","    for index in range(len(data_raw) - look_back):\n","        data.append(data_raw[index: index + look_back])\n","\n","    data = np.array(data);\n","    test_set_size = int(np.round(0.2*data.shape[0]));\n","    train_set_size = data.shape[0] - (test_set_size);\n","\n","    x_train = data[:train_set_size,:-1,:]\n","    y_train = data[:train_set_size,-1,:]\n","\n","    x_test = data[train_set_size:,:-1]\n","    y_test = data[train_set_size:,-1,:]\n","\n","    return [x_train, y_train, x_test, y_test]\n","\n","look_back = 30 # choose sequence length\n","x_train, y_train, x_test, y_test = load_data(df, look_back)\n","print('x_train.shape = ',x_train.shape)\n","print('y_train.shape = ',y_train.shape)\n","print('x_test.shape = ',x_test.shape)\n","print('y_test.shape = ',y_test.shape)"]},{"cell_type":"code","execution_count":7,"id":"3735c837","metadata":{"id":"3735c837","executionInfo":{"status":"ok","timestamp":1725097481617,"user_tz":-330,"elapsed":6,"user":{"displayName":"Harshit","userId":"17422353300963922472"}}},"outputs":[],"source":["x_train = torch.from_numpy(x_train).type(torch.Tensor)\n","x_test = torch.from_numpy(x_test).type(torch.Tensor)\n","y_train = torch.from_numpy(y_train).type(torch.Tensor)\n","y_test = torch.from_numpy(y_test).type(torch.Tensor)"]},{"cell_type":"code","execution_count":8,"id":"d1f73f58","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d1f73f58","executionInfo":{"status":"ok","timestamp":1725097486327,"user_tz":-330,"elapsed":4715,"user":{"displayName":"Harshit","userId":"17422353300963922472"}},"outputId":"254a5649-e69d-431a-b200-14be15ebf3d0"},"outputs":[{"output_type":"stream","name":"stdout","text":["LSTM(\n","  (lstm): LSTM(1, 30, num_layers=5, batch_first=True)\n","  (fc): Linear(in_features=30, out_features=1, bias=True)\n",")\n","22\n","torch.Size([120, 1])\n","torch.Size([120, 30])\n","torch.Size([120])\n","torch.Size([120])\n","torch.Size([120, 30])\n","torch.Size([120, 30])\n","torch.Size([120])\n","torch.Size([120])\n","torch.Size([120, 30])\n","torch.Size([120, 30])\n","torch.Size([120])\n","torch.Size([120])\n","torch.Size([120, 30])\n","torch.Size([120, 30])\n","torch.Size([120])\n","torch.Size([120])\n","torch.Size([120, 30])\n","torch.Size([120, 30])\n","torch.Size([120])\n","torch.Size([120])\n","torch.Size([1, 30])\n","torch.Size([1])\n"]}],"source":["input_dim = 1\n","hidden_dim = 30\n","num_layers = 5\n","output_dim = 1\n","\n","\n","# Here we define our model as a class\n","class LSTM(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n","        super(LSTM, self).__init__()\n","        # Hidden dimensions\n","        self.hidden_dim = hidden_dim\n","\n","        # Number of hidden layers\n","        self.num_layers = num_layers\n","\n","        # batch_first=True causes input/output tensors to be of shape\n","        # (batch_dim, seq_dim, feature_dim)\n","        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n","\n","        # Readout layer\n","        self.fc = nn.Linear(hidden_dim, output_dim)\n","    def forward(self, x):\n","        # Initialize hidden state with zeros\n","        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()\n","\n","        # Initialize cell state\n","        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_()\n","\n","        # We need to detach as we are doing truncated backpropagation through time (BPTT)\n","        # If we don't, we'll backprop all the way to the start even after going through another batch\n","        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n","\n","        # Index hidden state of last time step\n","        # out.size() --> 100, 32, 100\n","        # out[:, -1, :] --> 100, 100 --> just want last time step hidden states!\n","        out = self.fc(out[:, -1, :])\n","        # out.size() --> 100, 10\n","        return out\n","\n","model = LSTM(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, num_layers=num_layers)\n","loss_fn = torch.nn.MSELoss()\n","\n","optimiser = torch.optim.Adam(model.parameters(), lr=0.01)\n","print(model)\n","print(len(list(model.parameters())))\n","for i in range(len(list(model.parameters()))):\n","    print(list(model.parameters())[i].size())"]},{"cell_type":"code","execution_count":9,"id":"fXg6TPJrgmN9","metadata":{"id":"fXg6TPJrgmN9","executionInfo":{"status":"ok","timestamp":1725097486328,"user_tz":-330,"elapsed":34,"user":{"displayName":"Harshit","userId":"17422353300963922472"}}},"outputs":[],"source":["from sklearn.metrics import mean_absolute_error"]},{"cell_type":"code","source":[],"metadata":{"id":"3Ykv0KHCve5N"},"id":"3Ykv0KHCve5N","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"0qVglyg9vfKJ"},"outputs":[],"source":["files = os.listdir(dpath)\n","files.sort()\n","log = dict()\n","mpath = '/content/drive/My Drive/LAB/output_lstm/'\n","model = LSTM(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, num_layers=num_layers)\n","num_epochs = 100\n","optimiser = torch.optim.Adam(model.parameters(), lr=0.001)\n","\n","rmse = []\n","maes = []\n","\n","from tqdm import tqdm, trange\n","\n","for t in trange(num_epochs):\n","    for file in files:\n","        try:\n","            df = pd.read_csv(dpath + file).set_index('Date')\n","            df = df[['Close']]\n","            scaler = MinMaxScaler(feature_range=(-1, 1))\n","            df['Close'] = scaler.fit_transform(df['Close'].values.reshape(-1,1))\n","            look_back = 30 # choose sequence length\n","            x_train, y_train, x_test, y_test = load_data(df, look_back)\n","\n","            x_train = torch.from_numpy(x_train).type(torch.Tensor)\n","            x_test = torch.from_numpy(x_test).type(torch.Tensor)\n","            y_train = torch.from_numpy(y_train).type(torch.Tensor)\n","            y_test = torch.from_numpy(y_test).type(torch.Tensor)\n","\n","            loss_fn = torch.nn.MSELoss()\n","            hist = np.zeros(num_epochs)\n","            seq_dim =look_back-1\n","\n","            y_train_pred = model(x_train)\n","\n","            loss = loss_fn(y_train_pred, y_train)\n","            print(f\"{file}: Epoch \", t, \"MSE: \", loss.item(), end = '\\r')\n","            hist[t] = loss.item()\n","\n","            # Zero out gradient, else they will accumulate between epochs\n","            optimiser.zero_grad()\n","\n","            # Backward pass\n","            loss.backward()\n","\n","            # Update parameters\n","            optimiser.step()\n","\n","            y_test_pred = model(x_test)\n","\n","            # invert predictions\n","            if t == num_epochs - 1:\n","                y_train_pred = scaler.inverse_transform(y_train_pred.detach().numpy())\n","                y_train = scaler.inverse_transform(y_train.detach().numpy())\n","                y_test_pred = scaler.inverse_transform(y_test_pred.detach().numpy())\n","                y_test = scaler.inverse_transform(y_test.detach().numpy())\n","\n","\n","                mae = mean_absolute_error(y_test, y_test_pred)\n","                maes.append(mae)\n","                rmse.append(sqrt(mean_squared_error(y_test, y_test_pred)))\n","\n","        except:\n","            log[file] = 'ERROR'\n","\n","torch.save(model.state_dict(), mpath + 'global_lstm' + '.pth')"],"id":"0qVglyg9vfKJ"},{"cell_type":"code","execution_count":null,"id":"8084140d","metadata":{"colab":{"background_save":true},"id":"8084140d"},"outputs":[],"source":["import json\n","for key, val in log.items():\n","    log[key] = str(val)\n","with open(mpath + 'log.json', 'w') as json_file:\n","    json.dump(log, json_file)"]},{"cell_type":"markdown","id":"5f767fa3","metadata":{"id":"5f767fa3"},"source":["5555"]},{"cell_type":"code","execution_count":10,"id":"30c95183","metadata":{"id":"30c95183","executionInfo":{"status":"ok","timestamp":1725097486328,"user_tz":-330,"elapsed":32,"user":{"displayName":"Harshit","userId":"17422353300963922472"}}},"outputs":[],"source":["import numpy as np\n","import random\n","import pandas as pd\n","\n","import datetime\n","import math, time\n","import itertools\n","import datetime\n","from operator import itemgetter\n","from sklearn.metrics import mean_squared_error\n","from sklearn.preprocessing import MinMaxScaler\n","from math import sqrt\n","import torch\n","import torch.nn as nn\n","from torch.autograd import Variable\n","\n","import matplotlib.pyplot as plt\n","import os"]},{"cell_type":"code","execution_count":11,"id":"c04530a1","metadata":{"id":"c04530a1","executionInfo":{"status":"ok","timestamp":1725097486329,"user_tz":-330,"elapsed":32,"user":{"displayName":"Harshit","userId":"17422353300963922472"}}},"outputs":[],"source":["def load_data(stock, look_back):\n","    data_raw = stock.values # convert to numpy array\n","    data = []\n","\n","    # create all possible sequences of length look_back\n","    for index in range(len(data_raw) - look_back):\n","        data.append(data_raw[index: index + look_back])\n","\n","    data = np.array(data);\n","    test_set_size = int(np.round(0.2*data.shape[0]));\n","    train_set_size = data.shape[0] - (test_set_size);\n","\n","    x_train = data[:train_set_size,:-1,:]\n","    y_train = data[:train_set_size,-1,:]\n","\n","    x_test = data[train_set_size:,:-1]\n","    y_test = data[train_set_size:,-1,:]\n","\n","    return [x_train, y_train, x_test, y_test]"]},{"cell_type":"code","execution_count":12,"id":"d799ffe5","metadata":{"id":"d799ffe5","executionInfo":{"status":"ok","timestamp":1725097486329,"user_tz":-330,"elapsed":31,"user":{"displayName":"Harshit","userId":"17422353300963922472"}}},"outputs":[],"source":["def MAPE(Y_Predicted,Y_actual):\n","    mape = np.mean(np.abs((Y_actual - Y_Predicted)/Y_actual))*100\n","    return mape"]},{"cell_type":"code","execution_count":13,"id":"1d47fea6","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":696},"id":"1d47fea6","executionInfo":{"status":"error","timestamp":1725097569483,"user_tz":-330,"elapsed":2071,"user":{"displayName":"Harshit","userId":"17422353300963922472"}},"outputId":"49809383-24cc-4b93-96a0-363b872fb05d"},"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"Error(s) in loading state_dict for LSTM:\n\tsize mismatch for lstm.weight_ih_l0: copying a param with shape torch.Size([160, 1]) from checkpoint, the shape in current model is torch.Size([120, 1]).\n\tsize mismatch for lstm.weight_hh_l0: copying a param with shape torch.Size([160, 40]) from checkpoint, the shape in current model is torch.Size([120, 30]).\n\tsize mismatch for lstm.bias_ih_l0: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([120]).\n\tsize mismatch for lstm.bias_hh_l0: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([120]).\n\tsize mismatch for lstm.weight_ih_l1: copying a param with shape torch.Size([160, 40]) from checkpoint, the shape in current model is torch.Size([120, 30]).\n\tsize mismatch for lstm.weight_hh_l1: copying a param with shape torch.Size([160, 40]) from checkpoint, the shape in current model is torch.Size([120, 30]).\n\tsize mismatch for lstm.bias_ih_l1: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([120]).\n\tsize mismatch for lstm.bias_hh_l1: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([120]).\n\tsize mismatch for lstm.weight_ih_l2: copying a param with shape torch.Size([160, 40]) from checkpoint, the shape in current model is torch.Size([120, 30]).\n\tsize mismatch for lstm.weight_hh_l2: copying a param with shape torch.Size([160, 40]) from checkpoint, the shape in current model is torch.Size([120, 30]).\n\tsize mismatch for lstm.bias_ih_l2: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([120]).\n\tsize mismatch for lstm.bias_hh_l2: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([120]).\n\tsize mismatch for lstm.weight_ih_l3: copying a param with shape torch.Size([160, 40]) from checkpoint, the shape in current model is torch.Size([120, 30]).\n\tsize mismatch for lstm.weight_hh_l3: copying a param with shape torch.Size([160, 40]) from checkpoint, the shape in current model is torch.Size([120, 30]).\n\tsize mismatch for lstm.bias_ih_l3: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([120]).\n\tsize mismatch for lstm.bias_hh_l3: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([120]).\n\tsize mismatch for lstm.weight_ih_l4: copying a param with shape torch.Size([160, 40]) from checkpoint, the shape in current model is torch.Size([120, 30]).\n\tsize mismatch for lstm.weight_hh_l4: copying a param with shape torch.Size([160, 40]) from checkpoint, the shape in current model is torch.Size([120, 30]).\n\tsize mismatch for lstm.bias_ih_l4: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([120]).\n\tsize mismatch for lstm.bias_hh_l4: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([120]).\n\tsize mismatch for fc.weight: copying a param with shape torch.Size([1, 40]) from checkpoint, the shape in current model is torch.Size([1, 30]).","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-79f5fb7a2de8>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdates\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmdates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/LAB/output_lstm/global_lstm.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2188\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2189\u001b[0;31m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0m\u001b[1;32m   2190\u001b[0m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[1;32m   2191\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for LSTM:\n\tsize mismatch for lstm.weight_ih_l0: copying a param with shape torch.Size([160, 1]) from checkpoint, the shape in current model is torch.Size([120, 1]).\n\tsize mismatch for lstm.weight_hh_l0: copying a param with shape torch.Size([160, 40]) from checkpoint, the shape in current model is torch.Size([120, 30]).\n\tsize mismatch for lstm.bias_ih_l0: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([120]).\n\tsize mismatch for lstm.bias_hh_l0: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([120]).\n\tsize mismatch for lstm.weight_ih_l1: copying a param with shape torch.Size([160, 40]) from checkpoint, the shape in current model is torch.Size([120, 30]).\n\tsize mismatch for lstm.weight_hh_l1: copying a param with shape torch.Size([160, 40]) from checkpoint, the shape in current model is torch.Size([120, 30]).\n\tsize mismatch for lstm.bias_ih_l1: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([120]).\n\tsize mismatch for lstm.bias_hh_l1: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([120]).\n\tsize mismatch for lstm.weight_ih_l2: copying a param with shape torch.Size([160, 40]) from checkpoint, the shape in current model is torch.Size([120, 30]).\n\tsize mismatch for lstm.weight_hh_l2: copying a param with shape torch.Size([160, 40]) from checkpoint, the shape in current model is torch.Size([120, 30]).\n\tsize mismatch for lstm.bias_ih_l2: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([120]).\n\tsize mismatch for lstm.bias_hh_l2: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([120]).\n\tsize mismatch for lstm.weight_ih_l3: copying a param with shape torch.Size([160, 40]) from checkpoint, the shape in current model is torch.Size([120, 30]).\n\tsize mismatch for lstm.weight_hh_l3: copying a param with shape torch.Size([160, 40]) from checkpoint, the shape in current model is torch.Size([120, 30]).\n\tsize mismatch for lstm.bias_ih_l3: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([120]).\n\tsize mismatch for lstm.bias_hh_l3: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([120]).\n\tsize mismatch for lstm.weight_ih_l4: copying a param with shape torch.Size([160, 40]) from checkpoint, the shape in current model is torch.Size([120, 30]).\n\tsize mismatch for lstm.weight_hh_l4: copying a param with shape torch.Size([160, 40]) from checkpoint, the shape in current model is torch.Size([120, 30]).\n\tsize mismatch for lstm.bias_ih_l4: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([120]).\n\tsize mismatch for lstm.bias_hh_l4: copying a param with shape torch.Size([160]) from checkpoint, the shape in current model is torch.Size([120]).\n\tsize mismatch for fc.weight: copying a param with shape torch.Size([1, 40]) from checkpoint, the shape in current model is torch.Size([1, 30])."]}],"source":["from sklearn.metrics import mean_absolute_error\n","from sklearn.metrics import mean_squared_error\n","\n","input_dim = 1\n","hidden_dim = 30\n","num_layers = 5\n","output_dim = 1\n","model = LSTM(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, num_layers=num_layers)\n","\n","import matplotlib.dates as mdates\n","\n","model.load_state_dict(torch.load('/content/drive/My Drive/LAB/output_lstm/global_lstm.pth'))\n","model.eval()\n","\n","log_hist = \"\"\n","\n","\n","rmse = []\n","maes = []\n","\n","def infer(file):\n","    global log_hist\n","    dpath = \"/content/drive/My Drive/LAB/data/\"\n","    mpath = '/content/drive/My Drive/LAB/output_lstm/'\n","    df = pd.read_csv(dpath + file).set_index('Date')\n","    df.index = pd.to_datetime(df.index)\n","    df = df[['Close']]\n","    scaler = MinMaxScaler(feature_range=(-1, 1))\n","    df['Close'] = scaler.fit_transform(df['Close'].values.reshape(-1,1))\n","    look_back = 30 # choose sequence length\n","    x_train, y_train, x_test, y_test = load_data(df, look_back)\n","    x_train = torch.from_numpy(x_train).type(torch.Tensor)\n","    x_test = torch.from_numpy(x_test).type(torch.Tensor)\n","    y_train = torch.from_numpy(y_train).type(torch.Tensor)\n","    y_test = torch.from_numpy(y_test).type(torch.Tensor)\n","#     print(x_train, x_train.shape)\n","    with torch.no_grad():\n","        y_train_pred = model(x_train)\n","        y_test_pred = model(x_test)\n","    y_train_pred = scaler.inverse_transform(y_train_pred.detach().numpy())\n","    y_train = scaler.inverse_transform(y_train.detach().numpy())\n","    y_test_pred = scaler.inverse_transform(y_test_pred.detach().numpy())\n","    y_test = scaler.inverse_transform(y_test.detach().numpy())\n","\n","    mae = mean_absolute_error(y_test, y_test_pred)\n","    maes.append(mae)\n","    rmse.append(sqrt(mean_squared_error(y_test, y_test_pred)))\n","\n","    err_test, err_train = MAPE(y_test_pred, y_test), MAPE(y_train_pred, y_train)\n","\n","    logln = f\"{file.split()[0]} had {err_train}% train error and {err_test}% test error\\n\"\n","    # print(logln)\n","    log_hist += logln\n","\n","    figure, axes = plt.subplots(figsize=(15, 6))\n","    axes.xaxis.set_major_locator(mdates.AutoDateLocator())\n","    axes.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n","\n","    axes.plot(df[len(df)-len(y_test):].index, y_test, color = 'red', label = 'Real Stock Price')\n","    axes.plot(df[len(df)-len(y_test):].index, y_test_pred, color = 'blue', label = 'Predicted Stock Price')\n","    #axes.xticks(np.arange(0,394,50))\n","    plt.title(f'{file} Stock Price Prediction')\n","    plt.xlabel('Time')\n","    plt.ylabel('Stock Price')\n","    plt.legend()\n","    plt.savefig('/content/drive/My Drive/LAB/output_lstm/' + file.split('.')[0] + '.png')\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"id":"d4ae360c","metadata":{"colab":{"background_save":true},"collapsed":true,"id":"d4ae360c"},"outputs":[],"source":["for file in tqdm(files):\n","    try:\n","        infer(file)\n","    except:\n","        continue"]},{"cell_type":"code","execution_count":null,"id":"LIcZfl4uGV1y","metadata":{"colab":{"background_save":true},"id":"LIcZfl4uGV1y"},"outputs":[],"source":["with open('/content/drive/My Drive/LAB/output_lstm/LOG.log', 'w+') as f:\n","    f.write(log_hist)\n","f.close()"]},{"cell_type":"code","execution_count":null,"id":"6_41tZspGjLA","metadata":{"colab":{"background_save":true},"id":"6_41tZspGjLA"},"outputs":[],"source":["print(rmse)\n","print(maes)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":5}
